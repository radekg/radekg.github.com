<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on gruchalski.com</title>
    <link>https://gruchalski.com/tags/kafka/</link>
    <description>Recent content in kafka on gruchalski.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://gruchalski.com/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>I hacked infinite retention into my open source Kafka</title>
      <link>https://gruchalski.com/posts/2021-04-02-kafka-infinite-retention/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-04-02-kafka-infinite-retention/</guid>
      <description>Well, sort of. But bear with me.
background A couple of days ago, Confluent announced a ZooKeeper free Kafka 2.8 RC0 available for testing. A fantastic effort, great achievement by all the contributors who made it happen.
In the typical Hacker News fashion, a post about Kafka always triggers an inevitable “Puslar vs Kafka” discussion. These always remind me of one of my main gripes related to Kafka: no infinite retention.</description>
    </item>
    
    <item>
      <title>Kafka 2.8 is out in the wild and does not need ZooKeeper anymore</title>
      <link>https://gruchalski.com/posts/2021-03-31-kafka-2.8-does-not-need-zookeeper-anymore/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-03-31-kafka-2.8-does-not-need-zookeeper-anymore/</guid>
      <description>Long time coming but the KIP-5001 has finally landed. It&amp;rsquo;s official, Apache Kafka does not require ZooKeeper anymore. The KRaft, the Kafka Raft implementation, is not recommended for production yet. Full announcement from Confluent is here2.
Regardless, this is a fantastic milestone and a kudos to all the contributors for making this happen as the simplification in the operations will be significant.
taking it for a test drive First, generate a new cluster ID:</description>
    </item>
    
    <item>
      <title>The case for Kafka cold storage</title>
      <link>https://gruchalski.com/posts/2016-05-08-the-case-for-kafka-cold-storage/</link>
      <pubDate>Sun, 08 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2016-05-08-the-case-for-kafka-cold-storage/</guid>
      <description>It is entirely possible that what I am going to describe here is an edge case not many people hit with their Kafka deployments. However, in my experience, when Kafka is used to ingest large volumes of data, it makes perfect sense. Considering that every now and then people ask for a cold storage feature on the Kafka mailing list, I am not the only one who would find this useful.</description>
    </item>
    
  </channel>
</rss>
