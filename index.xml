<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gruchalski.com</title>
    <link>https://gruchalski.com/</link>
    <description>Recent content on gruchalski.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Feb 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://gruchalski.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>It&#39;s all about the the Iface name</title>
      <link>https://gruchalski.com/posts/2021-02-18-its-all-about-the-iface-name/</link>
      <pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-18-its-all-about-the-iface-name/</guid>
      <description>Last night&amp;rsquo;s problem with the second VMM conflicting on the network layer with the first one was indeed the veth0 name hard coded in firectl. I&amp;rsquo;ve added the --veth-iface-name argument to firectl and I am now able to start multiple VMMs on a single bridge.
sudo firectl \  --firecracker-binary=/usr/bin/firecracker \  --kernel=/firecracker/kernels/vmlinux-v5.8 \  --root-drive=/firecracker/filesystems/alpine-base-root.ext4 \  --cni-network=alpine \  --socket-path=/tmp/alpine.sock \  --ncpus=1 \  --memory=128 \  --veth-iface-name=vethalpine1 sudo firectl \  --firecracker-binary=/usr/bin/firecracker \  --kernel=/firecracker/kernels/vmlinux-v5.</description>
    </item>
    
    <item>
      <title>Bridging the Firecracker network gap</title>
      <link>https://gruchalski.com/posts/2021-02-17-bridging-the-firecracker-network-gap/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-17-bridging-the-firecracker-network-gap/</guid>
      <description>Today I have looked at creating my own bridge networks for Firecracker VMMs. I already used CNI setups when evaluating the HashiCorp Nomad firecracker task driver1. Back then I incorrectly stated that Firecracker depends on certain CNI plugins. It doesn&amp;rsquo;t, it can take advantage of any CNI setup as long as the tc-redirect-tap is in the chained plugins.
The Nomad task driver had some issues, briefly:
 every now and then, oddly, the task would never shut the VMM down and the only way to make the VMM gow down was to sudo kill nomad I tried updating the task driver to latest SDK version but I was not able to upgrade the Firecracker dependency past a specific commit, any version after that specific commit makes the VMM come up, the network setup to be there but the VMM is not reachable, really, really weird issue - reported it here  So today, I took a different route.</description>
    </item>
    
    <item>
      <title>Live resize Firecracker VMM drive</title>
      <link>https://gruchalski.com/posts/2021-02-16-live-resize-firecracker-vmm-drive/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-16-live-resize-firecracker-vmm-drive/</guid>
      <description>Towards the end of the Firecracker VMM with additional disks article1 I concluded that I didn&amp;rsquo;t know how to live resize an attached drive. It turns out it is possible and it&amp;rsquo;s very easy to do using the Firecracker VMM API.
To launch the VMM with the API, I have to drop the --no-api argument (obviously) and use --api-sock with the path to the socket file. In a production system, I&amp;rsquo;d use a directory other than /tmp.</description>
    </item>
    
    <item>
      <title>Firecracker VMM with additional disks</title>
      <link>https://gruchalski.com/posts/2021-02-14-firecracker-vmm-with-additional-disks/</link>
      <pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-14-firecracker-vmm-with-additional-disks/</guid>
      <description>Before looking at the networking options, I have looked at adding extra drives to my Firecracker VMMs. Storing data on the root file system will not scale well long term. Additional disks will be a good solution to persist application specific data across reboots and upgrades.
Create the disk on the host First, create an additional file system on the host:
dd if=/dev/zero of=&amp;#34;/firecracker/filesystems/alpine-vol2.ext4&amp;#34; bs=1M count=500 mkfs.ext4 &amp;#34;/firecracker/filesystems/alpine-vol2.ext4&amp;#34; Reconfigure the VMM Change the VMM drives configuration:</description>
    </item>
    
    <item>
      <title>Launching Alpine Linux on Firecracker like a boss</title>
      <link>https://gruchalski.com/posts/2021-02-13-launching-alpine-linux-on-firecracker-like-a-boss/</link>
      <pubDate>Sat, 13 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-13-launching-alpine-linux-on-firecracker-like-a-boss/</guid>
      <description>The quest to launch an ETCD cluster on Firecracker starts here.
In this post, I&amp;rsquo;m describing how I&amp;rsquo;ve built my initial Alpine 3.13 VMM with OpenSSH and a dedicated sudoer user. In AWS, when one launches a Ubuntu instance, one can access it via ssh ubuntu@&amp;lt;address&amp;gt;, a CentOS VM is ssh centos@&amp;lt;address&amp;gt;. At the end of this write up, I&amp;rsquo;ll have ssh alpine@&amp;lt;address&amp;gt;. This VMM will have access to the outside world so I can install additional software and even ping the BBC!</description>
    </item>
    
    <item>
      <title>My golang modules live in Athens</title>
      <link>https://gruchalski.com/posts/2021-02-10-my-golang-modules-live-in-athens/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-10-my-golang-modules-live-in-athens/</guid>
      <description>So I&amp;rsquo;ve been on the fence with the vendor directory.
On one hand, it&amp;rsquo;s great to have the modules in the project because it speeds up the build and serves as a safe storage.
On the other hand, it does increase the churn in the repository and creates a lot of duplication on disk because many projects often contain the same dependencies.
Since I do like holding on to my dependencies and go mod works great for me, I&amp;rsquo;ve decided to try out The Athens.</description>
    </item>
    
    <item>
      <title>Vault on Firecracker with CNI plugins and Nomad</title>
      <link>https://gruchalski.com/posts/2021-02-07-vault-on-firecracker-with-cni-plugins-and-nomad/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-07-vault-on-firecracker-with-cni-plugins-and-nomad/</guid>
      <description>It&amp;rsquo;s good to know how to set up Firecracker VM by hand but that&amp;rsquo;s definitely suboptimal long term. So today I am looking at setting up Firecracker with CNI plugins. Firecracker needs four CNI plugins to operate: ptp, firewall, host-local and tc-redirect-tap. First three come from the CNI plugins1 repository, the last one comes from AWS Labs tc-redirect-tap2 repository.
Golang CNI plugins and tc-redirect-tap require golang to build. I&amp;rsquo;m using 1.</description>
    </item>
    
    <item>
      <title>Taking Firecracker for a spin</title>
      <link>https://gruchalski.com/posts/2021-02-06-taking-firecracker-for-a-spin/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2021-02-06-taking-firecracker-for-a-spin/</guid>
      <description>Firecracker1 is recently making rounds on the internet as this relatively new, awesome technology for running lightweight VMs.
As something coming from AWS and powering AWS Lambda, my original perception was that it&amp;rsquo;s not easy to set up and use. However, this write from Julia Evans2 proved me wrong. So, as I have recently picked up a used Dell R720 with decent amount of RAM and CPUs, it was time to take these two for a spin together.</description>
    </item>
    
    <item>
      <title>Keycloak Authorization Services - RPT, permissions or a decision only</title>
      <link>https://gruchalski.com/posts/2020-09-16-keycloak-authorization-services-rpt-permissions-or-a-decision-only/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-16-keycloak-authorization-services-rpt-permissions-or-a-decision-only/</guid>
      <description>This is a clarification to the previous write up about Keycloak Authorization Services1. The documentation of the response_mode documents the two values which can be used: decision and permissions. In the first Keycloak article2, I have wrongly assumed that no response_mode in the grant_type=urn:ietf:params:oauth:grant-type:uma-ticket call implies the value of permissions.
Mmm, that was a wrong assumption.
Now, looking at the documentation and trying it out, the distinction seems pretty obvious. It turns out there are three types of responses for this grant_type.</description>
    </item>
    
    <item>
      <title>Authenticate to private JFrog npm registry</title>
      <link>https://gruchalski.com/posts/2020-09-09-authenticate-to-private-jfrog-npm-registry/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-09-authenticate-to-private-jfrog-npm-registry/</guid>
      <description>This always gets me, npm publish fails to authenticate:
npm ERR! code E401 npm ERR! Unable to authenticate, need: Basic realm=&amp;quot;Artifactory Realm&amp;quot; npm ERR! A complete log of this run can be found in: npm ERR! /Users/rad/.npm/_logs/...Z-debug.log The solution is:
 Sign-in to JFrog. Find Edit profile under the Welcome, ... menu. Put JFrog password in and unlock. Copy the encrypted password. Issue a curl request like this:  curl -u ${JFROG_USER}:${JFROG_ENCRYPTED_PASSWORD} https://${JFROG_ORG}.</description>
    </item>
    
    <item>
      <title>Multi-tenant Vault PKI with custom root PEM bundles</title>
      <link>https://gruchalski.com/posts/2020-09-09-multi-tenant-vault-pki-with-custom-root-pem-bundle/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-09-multi-tenant-vault-pki-with-custom-root-pem-bundle/</guid>
      <description>In the previous article1, I have investigated modern PKI software alternatives. One of the options on the list was HashiCorp Vault. The natural next step is to set up a Vault PKI.
This article documents setting up an imaginary multi-tenant Vault PKI with custom PEM bundles generated with OpenSSL. The steps the following:
 create a root CA with OpenSSL create intermediate CAs for imaginary clients with OpenSSL using HashiCorp Vault in development mode:  import custom bundle with root and intermediate certificates configure Vault roles issue a certificate    The method for generating the root and intermediate CAs comes from OpenSSL Certificate Authority guide written by Jamie Nguyen2.</description>
    </item>
    
    <item>
      <title>Certificate Authority is not Voodoo</title>
      <link>https://gruchalski.com/posts/2020-09-07-certificate-authority-is-not-voodoo/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-07-certificate-authority-is-not-voodoo/</guid>
      <description>Modern applications tend to get fairly complex pretty quick. A usual stack will consist of many moving parts. Starting from a cloud environment, maybe abstracted behind Kubernetes or Mesos, through multitude of web servers, GRPC services, to monitoring systems like Grafana, Jaeger, Prometheus, all fronted with load balancers or proxies like Traefik. Many of these components have fairly complex dependencies, ETCD or Zookeeper come to mind. All these power a highly dynamic environment where containers and virtual machines iterate and get replaced often.</description>
    </item>
    
    <item>
      <title>Keycloak Authorization Services - retrieving the decision only</title>
      <link>https://gruchalski.com/posts/2020-09-06-keycloak-authorization-services-decision-only/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-06-keycloak-authorization-services-decision-only/</guid>
      <description>In Introduction to Keycloak Authorization Services 1, I have described how to use the Authorization Services to find out if the user has access to certain resources.
I have done so by asking Keycloak to issue an access token with a special grant_type with the value of urn:ietf:params:oauth:grant-type:uma-ticket which returned a list of permissions the has access to.
The request looked like this:
curl --silent -X POST \  ${KEYCLOAK_TOKEN_URL} \  -H &amp;#34;Authorization: Bearer ${access_token}&amp;#34; \  --data &amp;#34;grant_type=urn:ietf:params:oauth:grant-type:uma-ticket&amp;#34; \  --data &amp;#34;audience=customers&amp;#34; \  --data &amp;#34;permission=CustomerB#customer-b&amp;#34; | jq &amp;#39;.</description>
    </item>
    
    <item>
      <title>Introduction to Keycloak Authorization Services</title>
      <link>https://gruchalski.com/posts/2020-09-05-introduction-to-keycloak-authorization-services/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-05-introduction-to-keycloak-authorization-services/</guid>
      <description>As the number of applications and websites in the organization grows, the developer will inevitably receive a request to implement Single Sign-On. Single Sign-On (SSO for short) is an authentication scheme allowing the user to log in with a single set of credentials and share the session across multiple, independent, potentially unrelated systems.
The savvy developer will roll out Keycloak, enable Standard Flow client, maybe enable some of the social login options, like GitHub, Google or Facebook and call it a day.</description>
    </item>
    
    <item>
      <title>About Radek Gruchalski</title>
      <link>https://gruchalski.com/about/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/about/</guid>
      <description>Geschäftsführer / Software Engineer @ Klarrio GmbH Managing director and software engineer at Klarrio GmbH.
Software engineer by trade. With over twenty years of experience specializing in distributed and back end systems: R&amp;amp;D, development and operations. No stranger to the DevOps and CI/CD world. Author of open source tools.
Computer polyglot who delivered production systems in multiple technologies, including: Scala, Erlang, golang, Java, Ruby, Python and JavaScript deployed in Amazon Web Services, Google Cloud Platform, OpenStack and SoftLayer.</description>
    </item>
    
    <item>
      <title>Keycloak With Docker Compose</title>
      <link>https://gruchalski.com/posts/2020-09-03-keycloak-with-docker-compose/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2020-09-03-keycloak-with-docker-compose/</guid>
      <description>Keycloak is an open source Identity and Access Management System developed as a JBoss community project under the stewardship of Red Hat. Keycloak makes it is easy to secure apps and services written in many technologies using a large number client libraries.
Out of the box, we get things like Single Sign-On, Identity Brokering and Social Login, User Federation and Authorization Services.
With little to no code, we can give users of our apps the ability to sign in with Identity Providers like GitHub, Twitter or Google.</description>
    </item>
    
    <item>
      <title>Publish to Maven Central via Sonatype with SBT</title>
      <link>https://gruchalski.com/posts/2017-01-31-publish-to-maven-central-via-sonatype-with-sbt/</link>
      <pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2017-01-31-publish-to-maven-central-via-sonatype-with-sbt/</guid>
      <description>First, create an account on the Sonatype JIRA, unless you have one. For the new group ID, create a ticket using the form under this URI. Once requested, wait for the ticket to go into Resolved state. When this happens, you can publish your project to Sonatype.
To do so, configure your SBT project. Add the following lines to your project/plugins.sbt:
addSbtPlugin(&amp;#34;org.xerial.sbt&amp;#34; % &amp;#34;sbt-sonatype&amp;#34; % &amp;#34;1.1&amp;#34;) addSbtPlugin(&amp;#34;com.jsuereth&amp;#34; % &amp;#34;sbt-pgp&amp;#34; % &amp;#34;1.</description>
    </item>
    
    <item>
      <title>The case for Kafka cold storage</title>
      <link>https://gruchalski.com/posts/2016-05-08-the-case-for-kafka-cold-storage/</link>
      <pubDate>Sun, 08 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2016-05-08-the-case-for-kafka-cold-storage/</guid>
      <description>It is entirely possible that what I am going to describe here is an edge case not many people hit with their Kafka deployments. However, in my experience, when Kafka is used to ingest large volumes of data, it makes perfect sense. Considering that every now and then people ask for a cold storage feature on the Kafka mailing list, I am not the only one who would find this useful.</description>
    </item>
    
    <item>
      <title>Apache Spark on Mesos with Docker bridge networking</title>
      <link>https://gruchalski.com/posts/2015-11-23-apache-spark-on-mesos-with-docker-bridge-networking/</link>
      <pubDate>Mon, 23 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2015-11-23-apache-spark-on-mesos-with-docker-bridge-networking/</guid>
      <description>About two weeks ago, Virdata released a set of patches for Apache Spark enabling Spark to work on Mesos with Docker bridge networking. We are using these in production for our multi tenant Spark environment.
SPARK-11638: Spark patches All patches for all components described below are available in Spark JIRA. We&amp;rsquo;ve released patches for all versions of Spark available at the time of creating them - from 1.4.0 to 1.5.2. We have also released patches for Akka 2.</description>
    </item>
    
    <item>
      <title>Gossiperl at EUC 2015 and next steps</title>
      <link>https://gruchalski.com/posts/2015-06-17-gossiperl-at-euc-2015-and-next-steps/</link>
      <pubDate>Wed, 17 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2015-06-17-gossiperl-at-euc-2015-and-next-steps/</guid>
      <description>Wow. It’s difficult to believe it’s been almost a week since I gave a talk about gossip protocols at Erlang User Conference in Stockholm. It was a fantastic event, great agenda, great topics, fantastic networking. EUC is one of those events you should attend, you will not regret it. No matter if you are interested in Erlang/Elixir or not. Big “Thank You” to all who made it happen.
EUC2015 was also a place of first public appearance of Gossiperl.</description>
    </item>
    
    <item>
      <title>Control Keynote presentation with your mobile browser</title>
      <link>https://gruchalski.com/posts/2015-05-11-control-keynote-presnetation-with-your-mobile-browser/</link>
      <pubDate>Mon, 11 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2015-05-11-control-keynote-presnetation-with-your-mobile-browser/</guid>
      <description>A little moan to start with&amp;hellip; I owned a mid 2009 MacBook Pro, I never used it for presenting stuff to others but I actually bought a remote control for it. The computer cost me a lot of money, it was top end stuff when it was bought. The remote control cost me the money as well. I also have a copy of Keynote. It also cost me money. A while ago I&amp;rsquo;ve switched to a new MacBook, the Retina one, top end as well.</description>
    </item>
    
    <item>
      <title>Crowd sourced unit testing / CI</title>
      <link>https://gruchalski.com/posts/2015-04-21-crowd-sourced-unit-testing-ci/</link>
      <pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2015-04-21-crowd-sourced-unit-testing-ci/</guid>
      <description>Unit testing has evolved a long way over the years, continuous integration services even more so. Few years back, when mentioning CI, Jenkins was the only reasonable choice someone would take. It was kind of easy to set up, depending on what one was planning to do with it. Looking at this space today there are plenty of services offering painless CI for the masses. The most known one - Travis CI.</description>
    </item>
    
    <item>
      <title>State of gossiperl and some JavaScript Thrift goodies</title>
      <link>https://gruchalski.com/posts/2015-01-05-state-of-gossiperl-and-some-javascript-thrift-goodies/</link>
      <pubDate>Mon, 05 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2015-01-05-state-of-gossiperl-and-some-javascript-thrift-goodies/</guid>
      <description>The gossiperl project is growing. I had a great, productive, working Christmas break, implementing a number of client libraries for the message bus. In the last couple of weeks a number of client libraries for gossiperl have been released. The full list now includes:
 Ruby JVM with examples in Clojure and Scala .NET as a mono project Erlang  And the most exciting so far — gossiperl client Chrome extension.</description>
    </item>
    
    <item>
      <title>Gossiperl   gossip middleware in Erlang</title>
      <link>https://gruchalski.com/posts/2014-12-09-gossiperl-gossip-middleware-in-erlang/</link>
      <pubDate>Tue, 09 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2014-12-09-gossiperl-gossip-middleware-in-erlang/</guid>
      <description>Today I&amp;rsquo;ve released a project called gossiperl. Gossiperl is a language agnostic gossip middleware written in Erlang. The purpose of the project was purely research on gossip based systems, as well as, learning Erlang.
Main intent was to create a common communication middleware enabled over gossip using a standard binary transport mechanism. Gossiperl is a result of over 6 months of research, reading, learning, planning and implementation. Gossiperl uses Apache Thrift binary serialisation over UDP.</description>
    </item>
    
    <item>
      <title>Apache Thrift via UDP in Erlang</title>
      <link>https://gruchalski.com/posts/2014-10-12-apache-thrift-via-udp-in-erlang/</link>
      <pubDate>Sun, 12 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2014-10-12-apache-thrift-via-udp-in-erlang/</guid>
      <description>A few months ago I have started learning Erlang, mostly for fun but it was right about time to jump on the functional bandwagon. The best way to learn a new language is to find an engaging project, in my case its been something what has been on my mind for quite a while: a cloud communication protocol / framework for distributed computing. Some basic principles of what it is about can be found here: CloudDDS.</description>
    </item>
    
    <item>
      <title>OpenStack Devstack up and running with Vagrant, in 12.5 minutes</title>
      <link>https://gruchalski.com/posts/2014-05-20-openstack-devstack-up-and-running-with-vagrant-in-125-minutes/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2014-05-20-openstack-devstack-up-and-running-with-vagrant-in-125-minutes/</guid>
      <description>I&amp;rsquo;d like to develop for OpenStack The eaiest way to start, is to use a project called devstack. Devstack is:
 A documented shell script to build complete OpenStack development environments.
 It looks promising. Unfortunately, the script is not as simple as what is claimed on the website:
git clone https://github.com/openstack-dev/devstack.git # configure, while optional... cd devstack; ./stack.sh  There be Dragons.
So? After looking at a number of different search results on the Internets, digging through some Chef cookbooks, Puppet stuff, here&amp;rsquo;s a Vagrant file to set up Devstack using Vagrant (Ubuntu 12.</description>
    </item>
    
    <item>
      <title>Erflux, InfluxDB client for Erlang</title>
      <link>https://gruchalski.com/posts/2014-10-21-erflux-influxdb-client-for-erlang/</link>
      <pubDate>Mon, 21 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2014-10-21-erflux-influxdb-client-for-erlang/</guid>
      <description>It’s been already a month since I released erflux on github. Erflux is an Erlang client for InfluxDB HTTP protocol.
Installation {deps, [ {erflux, &amp;#34;.*&amp;#34;, {git, &amp;#34;git://github.com/radekg/erflux.git&amp;#34;, {tag, &amp;#34;version-1&amp;#34;}}} }]} and run
./rebar get-deps  Configuration Erflux allows configuring a number of parameters:
 InfluxDB host, default 127.0.0.1 InfluxDB port, default 8086 username, default: root password, default: root SSL usage, default: false timeout, default: infinity  The simplest way of applying configuration is to use application:set_env, like the example below:</description>
    </item>
    
    <item>
      <title>Apache Zookeeper authentication</title>
      <link>https://gruchalski.com/posts/2013-06-24-apache-zookeeper-authentication/</link>
      <pubDate>Mon, 24 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2013-06-24-apache-zookeeper-authentication/</guid>
      <description>The problem One of my Zookeeper clusters has to be available to everyone. But I want to make sure only specific known hosts are allowed to connect. The problem was, those known hosts are dynamic and I didn&amp;rsquo;t want any configuration for this component. The servers are running in the cloud, they come and go.
At Technicolor, we use Chef to manage all our boxes. Every box is registered on the Chef server, we know every private and public IP address of every server within our setup.</description>
    </item>
    
    <item>
      <title>Git: chopping out part of the repo into a separate repo</title>
      <link>https://gruchalski.com/posts/2013-03-22-git-chopping-out-part-of-the-repo-into-a-separate-repo/</link>
      <pubDate>Fri, 22 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2013-03-22-git-chopping-out-part-of-the-repo-into-a-separate-repo/</guid>
      <description>I had to cut out cookbooks/nodejs from the develop into a separate repository and move develop to master.
 The problem is, there is a git repository called XYZ with the following structure:
 cookbooks  nodejs ... mysql ...   other_stuff ...  and following branches:
 refs/heads/master refs/heads/develop  I had to cut out cookbooks/nodejs from the develop into a separate repository and move develop to master.</description>
    </item>
    
    <item>
      <title>Setting up knife ec2</title>
      <link>https://gruchalski.com/posts/2013-03-07-setting-up-knife-ec2/</link>
      <pubDate>Thu, 07 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2013-03-07-setting-up-knife-ec2/</guid>
      <description>I keep getting Fog::Compute::AWS::NotFound: The key pair ... does not exist error!
 How to solve this problem isn&amp;rsquo;t explained well enough anywhere.
Install knife-ec2 first:
sudo gem install knife-ec2  Then I added this to my knife.rb:
# key name, as defined in EC2 Key Pairs, # this value has to be exactly the same as the one in the management console: knife[:aws_ssh_key_id] = &amp;#34;my-ec2-key&amp;#34; # AWS ID/SECRET: knife[:aws_access_key_id] = &amp;#34;.</description>
    </item>
    
    <item>
      <title>DevOps box</title>
      <link>https://gruchalski.com/posts/2013-03-05-devops-box/</link>
      <pubDate>Tue, 05 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gruchalski.com/posts/2013-03-05-devops-box/</guid>
      <description>{% include collecttags.html %}
 I was asked to build a box with all the monitoring tools required. Chef, Logstash, Ganglia and Monit were selected. Here&amp;rsquo;s a core dump.
 In this post I&amp;rsquo;m going to describe how to setup a box containing following elements:
 Opsworks Chef Server Logstash indexer with Redis as an incoming queue Kibana Ganglia collector Monit with the log shipped to logstash M/Monit   I have this nasty habit - this whole thing is running as root.</description>
    </item>
    
  </channel>
</rss>